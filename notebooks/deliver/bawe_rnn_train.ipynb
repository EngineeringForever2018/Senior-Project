{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import Embedding\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(Path('..')))\n",
    "\n",
    "from notebooks.datatools import EqualOpDataLoader, Preprocessor  # noqa\n",
    "from notebooks.nets import EuclideanDiscriminator, PackedEmbedder, ParEncoder, SentenceEncoder, StyleEncoder  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "major-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_dir = Path('../runs')\n",
    "\n",
    "dev = torch.device(0)\n",
    "writer = SummaryWriter(join(writer_dir, f'{datetime.now()}-bawe-par-encoder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "major-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data_dir = Path('../data/preprocess')\n",
    "resources_dir = Path('../resources')\n",
    "\n",
    "train_data = torch.load(join(preprocessed_data_dir, 'bawe_train_data.pt'))\n",
    "train_sentence_lengths = torch.load(join(preprocessed_data_dir,\n",
    "                                         'bawe_train_sentence_lengths.pt'))\n",
    "train_labels = torch.load(join(preprocessed_data_dir, 'bawe_train_labels.pt'))\n",
    "\n",
    "valid_data = torch.load(join(preprocessed_data_dir, 'bawe_valid_data.pt'))\n",
    "valid_sentence_lengths = torch.load(join(preprocessed_data_dir,\n",
    "                                         'bawe_valid_sentence_lengths.pt'))\n",
    "valid_labels = torch.load(join(preprocessed_data_dir, 'bawe_valid_labels.pt'))\n",
    "\n",
    "with open(join(resources_dir, 'pos_vocab.p'), 'rb') as f:\n",
    "    pos_vocab = pickle.load(f)\n",
    "\n",
    "train_set = TensorDataset(train_data, train_sentence_lengths, train_labels)\n",
    "valid_set = TensorDataset(valid_data, valid_sentence_lengths, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "waiting-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = PackedEmbedder(Embedding(len(pos_vocab), 100,\n",
    "                                    padding_idx=pos_vocab['<pad>']))\n",
    "sentence_encoder = SentenceEncoder(100, 100)\n",
    "par_encoder = ParEncoder(100, 100)\n",
    "\n",
    "style_encoder = StyleEncoder(embedder, sentence_encoder, par_encoder).to(dev)\n",
    "style_discriminator = EuclideanDiscriminator().to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changed-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.seed()\n",
    "\n",
    "# Hyperparameters\n",
    "batch_count = 1000\n",
    "lr = 1e-6\n",
    "opt = optim.SGD([{'params': style_discriminator.parameters()},\n",
    "                 {'params': style_encoder.parameters()}], lr=lr)\n",
    "criterion = mse_loss\n",
    "bs = 75\n",
    "\n",
    "preprocessor = Preprocessor(dev)\n",
    "train_dl = EqualOpDataLoader(train_set, bs=bs, collate_fn=preprocessor)\n",
    "valid_dl = EqualOpDataLoader(valid_set, bs=bs, collate_fn=preprocessor)\n",
    "\n",
    "\n",
    "def fit(validate=True, validate_every=100):\n",
    "    train_dl.batch_count = batch_count\n",
    "    for index, ((x1b, y1b), (x2b, y2b)) in tqdm(enumerate(train_dl),\n",
    "                                                total=len(train_dl)):\n",
    "        x1_encoding = style_encoder(x1b)\n",
    "        x2_encoding = style_encoder(x2b)\n",
    "\n",
    "        pred = style_discriminator(x1_encoding, x2_encoding).squeeze(1)\n",
    "\n",
    "        yb = y_difference(y1b, y2b).to(dtype=torch.float)\n",
    "\n",
    "        loss = criterion(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        writer.add_scalar('Training Loss', loss, index)\n",
    "        writer.flush()\n",
    "\n",
    "        if validate:\n",
    "            if index % 100 == 0:\n",
    "                valid_loss, valid_acc = evaluate(valid_dl, give_acc=True)\n",
    "                writer.add_scalar('Validation Loss', valid_loss, index)\n",
    "                writer.add_scalar('Validation Accuracy', valid_acc, index)\n",
    "                writer.flush()\n",
    "\n",
    "\n",
    "def y_difference(y1, y2):\n",
    "    return torch.logical_not((y1 == y2)).to(dtype=int).to(dev)\n",
    "\n",
    "\n",
    "def evaluate(dl, give_acc=False):\n",
    "    with torch.no_grad():\n",
    "        preds_y = [(style_discriminator(style_encoder(x1b),\n",
    "                                        style_encoder(x2b)),\n",
    "                    y_difference(y1b, y2b))\n",
    "                   for (x1b, y1b), (x2b, y2b) in dl]\n",
    "\n",
    "        losses = [criterion(preds_b.squeeze(1), yb) for preds_b, yb in preds_y]\n",
    "        loss = sum(losses) / len(losses)\n",
    "\n",
    "        if give_acc:\n",
    "            accs = [accuracy(preds_b, yb) for preds_b, yb in preds_y]\n",
    "            acc = sum(accs) / len(accs)\n",
    "\n",
    "            return loss, acc\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def accuracy(out, y):\n",
    "    preds = out > 0.5\n",
    "    return (preds == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prostate-bacteria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1000/1000 [05:06<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solar-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dir = Path('../outputs')\n",
    "if not os.path.isdir(outputs_dir):\n",
    "    os.mkdir(outputs_dir)\n",
    "\n",
    "torch.save(style_encoder.state_dict(),\n",
    "           join(outputs_dir, 'bawe_style_encoder_sd.pt'))\n",
    "torch.save(style_discriminator.state_dict(),\n",
    "           join(outputs_dir, 'bawe_style_discriminator_sd.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seeing-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:avpd]",
   "language": "python",
   "name": "conda-env-avpd-xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
